spark-shell

// for checking your warehouse dir
//spark.conf.get("spark.sql.warehouse.dir")

copy the hive-site file from hive/conf folder to spark/conf
----------------------------------------------------------
sudo cp /usr/local/hive/conf/hive-site.xml /usr/local/spark/conf


import org.apache.spark.sql.hive.HiveContext

val sqlContext = new HiveContext(sc)

val customers = sqlContext.sql("select * from retail.customer")

customers.collect.foreach(println);

customers.registerTempTable("customer");

val topprof = spark.sql("select profession, count(*) as headcount from customer group by profession order by headcount desc LIMIT 5")


Create a new table in hive metastore
-------------------------------------
sqlContext.sql("CREATE TABLE IF NOT EXISTS default.employee_spark(id INT, name STRING, city String) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' LINES TERMINATED BY '\n'")

Load the data in the table
--------------------------
sqlContext.sql("LOAD DATA LOCAL INPATH '/home/hduser/employee.txt' INTO TABLE default.employee_spark")


list the databases
------------------
spark.catalog.listDatabases.show(false)


List the tables - managed and views
------------------------------------
spark.catalog.listTables("crif").show(false)

spark.catalog.listTables("college").show(false)


